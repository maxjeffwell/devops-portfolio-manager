apiVersion: batch/v1
kind: CronJob
metadata:
  name: doppler-secrets-backup
  labels:
    app: doppler-secrets-backup
spec:
  schedule: "0 5 * * 0"
  concurrencyPolicy: Forbid
  successfulJobsHistoryLimit: 3
  failedJobsHistoryLimit: 3
  jobTemplate:
    spec:
      ttlSecondsAfterFinished: 3600
      template:
        metadata:
          labels:
            app: doppler-secrets-backup
        spec:
          restartPolicy: OnFailure
          containers:
          - name: doppler-export
            image: alpine:3.21
            imagePullPolicy: IfNotPresent
            command:
            - /bin/sh
            - -c
            - |
              set -e
              apk add --no-cache curl openssl aws-cli > /dev/null 2>&1
              TIMESTAMP=$(date +%Y%m%d-%H%M%S)

              echo "[$(date)] Starting Doppler secrets cold storage export..."

              # Download all secrets via Doppler API
              HTTP_CODE=$(curl -s -o /tmp/secrets.json -w "%{http_code}" \
                "https://api.doppler.com/v3/configs/config/secrets/download?format=json" \
                -H "authorization: Bearer ${DOPPLER_TOKEN}")

              if [ "$HTTP_CODE" != "200" ]; then
                echo "ERROR: Doppler API returned HTTP ${HTTP_CODE}"
                exit 1
              fi

              SECRET_COUNT=$(cat /tmp/secrets.json | grep -c '"' | head -1)
              echo "[$(date)] Downloaded secrets from Doppler"

              # Encrypt with AES-256-CBC using the encryption passphrase
              openssl enc -aes-256-cbc -salt -pbkdf2 -iter 100000 \
                -in /tmp/secrets.json \
                -out "/tmp/doppler-secrets-${TIMESTAMP}.enc" \
                -pass pass:"${ENCRYPTION_PASSPHRASE}"

              # Securely delete plaintext
              rm -f /tmp/secrets.json

              SIZE=$(du -h "/tmp/doppler-secrets-${TIMESTAMP}.enc" | cut -f1)
              echo "[$(date)] Encrypted backup: ${SIZE}"

              # Upload to B2
              aws s3 cp "/tmp/doppler-secrets-${TIMESTAMP}.enc" \
                "s3://${B2_BUCKET}/doppler-backups/doppler-secrets-${TIMESTAMP}.enc" \
                --endpoint-url="${B2_ENDPOINT}"

              echo "[$(date)] Uploaded to B2"

              # Clean up
              rm -f "/tmp/doppler-secrets-${TIMESTAMP}.enc"

              # Keep only last 12 backups (3 months of weekly)
              aws s3 ls "s3://${B2_BUCKET}/doppler-backups/" \
                --endpoint-url="${B2_ENDPOINT}" | sort | head -n -12 | while read -r line; do
                FILE_NAME=$(echo "$line" | awk '{print $NF}')
                if [ -n "$FILE_NAME" ]; then
                  echo "Deleting old backup: $FILE_NAME"
                  aws s3 rm "s3://${B2_BUCKET}/doppler-backups/${FILE_NAME}" \
                    --endpoint-url="${B2_ENDPOINT}"
                fi
              done

              echo "[$(date)] Doppler secrets backup complete!"
            env:
            - name: DOPPLER_TOKEN
              valueFrom:
                secretKeyRef:
                  name: doppler-token-auth
                  key: dopplerToken
            - name: ENCRYPTION_PASSPHRASE
              valueFrom:
                secretKeyRef:
                  name: doppler-backup-encryption
                  key: passphrase
            - name: B2_BUCKET
              value: "Marmoset"
            - name: B2_ENDPOINT
              value: "https://s3.us-east-005.backblazeb2.com"
            - name: AWS_ACCESS_KEY_ID
              valueFrom:
                secretKeyRef:
                  name: velero-b2-credentials
                  key: aws_access_key_id
            - name: AWS_SECRET_ACCESS_KEY
              valueFrom:
                secretKeyRef:
                  name: velero-b2-credentials
                  key: aws_secret_access_key
            resources:
              requests:
                cpu: 50m
                memory: 64Mi
              limits:
                cpu: 200m
                memory: 128Mi
