# Default values for IntervalAI
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

replicaCount: 1

image:
  server:
    repository: maxjeffwell/spaced-repetition-capstone-server
    tag: 20260116-084226-45e5dfe
    pullPolicy: Always
  client:
    repository: maxjeffwell/spaced-repetition-capstone-client
    tag: 20260116-084226-45e5dfe
    pullPolicy: Always

imagePullSecrets: []
nameOverride: ""
fullnameOverride: ""

serviceAccount:
  create: false
  annotations: {}
  name: ""

podAnnotations:
  prometheus.io/scrape: "true"
  prometheus.io/port: "8080"
  prometheus.io/path: "/metrics"

podSecurityContext:
  fsGroup: 2000

securityContext:
  capabilities:
    drop:
    - ALL
  readOnlyRootFilesystem: false
  runAsNonRoot: false
  runAsUser: 1001

# Client-specific security context (nginx needs to bind to port 80)
securityContextClient:
  capabilities:
    drop:
    - ALL
  readOnlyRootFilesystem: false
  runAsNonRoot: false

service:
  server:
    type: ClusterIP
    port: 8080
    targetPort: 8080
    nodePort: 30786
  client:
    type: NodePort
    port: 80
    targetPort: 80
    nodePort: 30787

ingress:
  enabled: false
  className: "nginx"
  annotations:
    cert-manager.io/cluster-issuer: "letsencrypt-prod"
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
  hosts:
    - host: intervalai.el-jefe.me
      paths:
        - path: /api
          pathType: Prefix
          backend:
            service:
              name: intervalai-server
              port: 8080
        - path: /
          pathType: Prefix
          backend:
            service:
              name: intervalai-client
              port: 80
  tls:
    - secretName: intervalai-tls
      hosts:
        - intervalai.el-jefe.me

resources:
  server:
    limits:
      cpu: 1000m
      memory: 1Gi
    requests:
      cpu: 250m
      memory: 512Mi
  client:
    limits:
      cpu: 200m
      memory: 256Mi
    requests:
      cpu: 100m
      memory: 128Mi

autoscaling:
  enabled: true
  minReplicas: 1
  maxReplicas: 10
  targetCPUUtilizationPercentage: 80
  targetMemoryUtilizationPercentage: 80

nodeSelector: {}

tolerations: []

affinity: {}

# MongoDB configuration
mongodb:
  enabled: true
  auth:
    enabled: true
    rootPassword: "intervalai-root-password"
    username: "intervalai"
    password: "intervalai-password"
    database: "intervalai"
  persistence:
    enabled: true
    size: 8Gi
    storageClass: ""
  resources:
    limits:
      cpu: 500m
      memory: 512Mi
    requests:
      cpu: 250m
      memory: 256Mi
  # Connection Pool Configuration
  # These settings prevent connection exhaustion under load
  pool:
    # Minimum number of connections to maintain
    minSize: 10
    # Maximum number of connections allowed (higher for ML workloads)
    maxSize: 100
    # Time (ms) before idle connections are closed
    maxIdleTimeMs: 30000
    # Timeout (ms) for waiting for available connection
    waitQueueTimeoutMs: 5000
    # Timeout (ms) for server selection
    serverSelectionTimeoutMs: 5000
  # Backup configuration (mongodump to Backblaze B2)
  backup:
    enabled: true
    # Run daily at 3 AM UTC
    schedule: "0 3 * * *"
    b2Bucket: "Marmoset"
    b2Endpoint: "https://s3.us-east-005.backblazeb2.com"
    b2SecretName: "velero-b2-credentials"

# Environment variables
env:
  server:
    - name: NODE_ENV
      value: "production"
    - name: PORT
      value: "8080"
    - name: MONGODB_URI
      valueFrom:
        secretKeyRef:
          name: intervalai-secret
          key: MONGODB_URI
    - name: JWT_SECRET
      valueFrom:
        secretKeyRef:
          name: intervalai-secret
          key: JWT_SECRET
    # MongoDB Connection Pool Configuration
    - name: MONGODB_POOL_MIN_SIZE
      value: "10"
    - name: MONGODB_POOL_MAX_SIZE
      value: "100"
    - name: MONGODB_MAX_IDLE_TIME_MS
      value: "30000"
    - name: MONGODB_WAIT_QUEUE_TIMEOUT_MS
      value: "5000"
    - name: MONGODB_SERVER_SELECTION_TIMEOUT_MS
      value: "5000"
    # CORS configuration
    - name: CLIENT_ORIGIN
      value: "https://intervalai-k8s.el-jefe.me"
    # Triton Inference Server Configuration (4-tiered fallback)
    - name: USE_TRITON
      value: "true"
    # Tier 1: Local GPU (GTX 1080 via Cloudflare tunnel)
    - name: PRIMARY_TRITON_URL
      value: "https://triton-gpu.el-jefe.me"
    # Tier 2: VPS CPU Triton
    - name: FALLBACK_TRITON_URL
      value: "http://triton-service:8000"
    - name: TRITON_MODEL_NAME
      value: "interval_ai"
    # Tier 3: RunPod Serverless GPU
    - name: RUNPOD_URL
      value: "https://api.runpod.ai/v2/7a2s0z4p6x0i8n"
    - name: RUNPOD_API_KEY
      valueFrom:
        secretKeyRef:
          name: intervalai-secret
          key: RUNPOD_API_KEY
    # Tier 4: TensorFlow.js (final fallback)
    - name: TFJS_BACKEND
      value: "auto"
  client:
    # Use empty string for relative URLs (nginx will proxy to backend via ingress)
    - name: REACT_APP_API_BASE_URL
      value: "/api"

# Health check configuration
livenessProbe:
  tcpSocket:
    port: 8080
  initialDelaySeconds: 30
  periodSeconds: 10
  timeoutSeconds: 5
  failureThreshold: 3

readinessProbe:
  tcpSocket:
    port: 8080
  initialDelaySeconds: 10
  periodSeconds: 5
  timeoutSeconds: 3
  failureThreshold: 3

# Client-specific probes (nginx on port 80)
livenessProbeClient:
  tcpSocket:
    port: 80
  initialDelaySeconds: 10
  periodSeconds: 10

readinessProbeClient:
  tcpSocket:
    port: 80
  initialDelaySeconds: 5
  periodSeconds: 5

# ConfigMap data
configMap:
  data:
    ML_MODEL_PATH: "/app/ml/saved-model"
    LOG_LEVEL: "info"
    CACHE_ENABLED: "true"

# ⚠️ CRITICAL SECURITY WARNING ⚠️
# NEVER commit real secrets to Git repositories!
# Use one of these secure alternatives:
#
# Option 1: External Secrets Operator (Recommended for production)
# externalSecret:
#   enabled: true
#   backendType: gcpSecretsManager  # or awsSecretsManager, azureKeyVault
#   projectID: your-project-id
#   data:
#     - key: intervalai-mongodb-uri
#       name: MONGODB_URI
#     - key: intervalai-jwt-secret
#       name: JWT_SECRET
#
# Option 2: Sealed Secrets (GitOps-friendly)
# kubectl create secret generic intervalai-secret \
#   --from-literal=MONGODB_URI='your-uri' \
#   --from-literal=JWT_SECRET='your-secret' \
#   --dry-run=client -o yaml | \
#   kubeseal -o yaml > sealed-secret.yaml
#
# Option 3: Helm values override at deploy time (for development)
# helm install intervalai . --set secret.data.MONGODB_URI='...' --set secret.data.JWT_SECRET='...'
#
# Secret data (base64 encoded)
# IMPORTANT: Replace these placeholders before deployment
secret:
  # Secrets managed externally - do not recreate
  data:
    # Base64 encode your MongoDB connection string:
    # echo -n "mongodb+srv://user:pass@cluster.mongodb.net/db" | base64
    MONGODB_URI: "REPLACE_WITH_BASE64_ENCODED_MONGODB_URI"

    # Base64 encode your JWT secret (use strong random string):
    # openssl rand -base64 32 | base64
    JWT_SECRET: "REPLACE_WITH_BASE64_ENCODED_JWT_SECRET"

# Monitoring
serviceMonitor:
  enabled: false
  interval: 30s
  scrapeTimeout: 10s
  labels: {}
